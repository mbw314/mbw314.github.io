<!DOCTYPE html>
<html>
<head>
	<title>Michael Bradford Williams | Linear Regression</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<link rel="stylesheet" type="text/css" href="./css/styles.css" />
	<link rel="shortcut icon" href="favicon.ico" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script language="JavaScript" type="text/javascript" src="./js/canvasUtil.js"></script>
  <script language="JavaScript" type="text/javascript" src="./js/regression.js"></script>
</head>

<body onload="init();">

<div class="content-row" id="header-row">
  <h2>Michael Bradford Williams</h2>
  <h3><a href="./index.html">Home</a> / <a href="./prog.html">Programming</a> / Linear Regression via Gradient Descent</h3>
</div>

<div class="content-row">

<p>
Given a set of data, <a href="http://en.wikipedia.org/wiki/Linear_regression">linear regression</a> is a way to
model to the data with a linear function. This can be done by minimizing a certain "cost function", which measures the deviation
of the data from the hypothesized linear model. The linear model with the least cost then has the "best fit" for the data.
</p>

<p>
Consider a set of \(m\) 2-dimensional data points
\[ \{(x_1, y_1), \dots, (x_m, y_m)\} \subset \mathbb{R}^2. \]
A linear model for
this data will be a line of the form \(y=mx+b\). We hope to find the values of slope \(m\) and intercept \(b\)
that minimize the cost function, which we take as the average of the squared vertical distances from the data points to the line:
\[ J(m, b) = \frac{1}{2m} \sum_{i=1}^m (m x_i + b - y_i)^2. \]
</p>

<p>
Note that \(J\) is a function of \(m\) and \(b\). How do we find the values of \(m\) and \(b\) that
minimize \(J(m, b)\)? This is a multivariable
<a href="http://en.wikipedia.org/wiki/Optimization_problem">optimization problem</a>, and one method is to
use <a href="http://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. The idea is that the (negative)
<a href="http://en.wikipedia.org/wiki/Gradient">gradient</a> of \(J\) is a vector \(-\nabla J\) that points in the direction of steepest
descrease of \(J\). So, if we incrementally follow the gradient of \(J\) through the \((m, b)\)-plane, we will eventually
reach a value \((m', b')\) that (approximately) minimizes \(J\).
</p>

<p>
In general, any minimizer found by gradient descent will only be local, but it turns out that the cost function above always
has a unique global minimizer, since it is a convex function. Here is the algorithm.
Again think of the variables \(m\) and \(b\) as a point \((m,b)\) in the plane.</p>
<ol>
<li>Randomly select initial values \((m, b)\), and choose a small number \(\alpha > 0\).</li>
<li>Update \((m,b)\) according to the following replacement:</li>
\[ (m, b) \longleftarrow (m, b) - \alpha \nabla J(m, b). \]
<li>Repeat Step 2 as many times as needed.</li>
</ol>
<p>The gradient is just the vector of partial derivatives of \(J\):
\[ \nabla J(m, b)
= \left( \frac{\partial J}{\partial m}(m, b), \frac{\partial J}{\partial b}(m, b) \right)
= \left( \frac{1}{m} \sum_{i=1}^m (m x_i + b - y_i) x_i, \frac{1}{m} \sum_{i=1}^m (m x_i + b - y_i) \right). \]
</p>

<p>
One can also consider more complicated models, such as quadratics (\(y = a x^2 + b x + c\)) or cubics
 (\(y = a x^3 + b x^2 + c x + d\)). Gradient descent still works in such cases, with modification
 to the cost function.
</p>

<p>
The app below illustrates how gradient descent finds the linear/quadratic/cubic curve of best fit. Random
data is selected, and you can initiate Step 2 in the gradient descent algorithm. The number \(\alpha\) is
called the "learning rate" and can also be controlled.
</p>

</div>

<div class="content-row">
	<table border="0" align="center">
		<tr>
			<td><b>Regression Type:</b>
			</td>
			<td>
				<form name="controls">
				Linear<input type="radio" name="regtype" value="linear" checked="yes">
				Quadratic<input type="radio" name="regtype" value="quadratic">
	      Cubic<input type="radio" name="regtype" value="cubic">
	      <b>Learning Rate</b>
	      <select name="learning_rate">
	        <option value="0.1">0.1</option>
	        <option value="0.3">0.3</option>
	        <option value="1.0" selected="selected">1.0</option>
	        <option value="1.3">1.3</option>
	        <option value="2.0">2.0</option>
	      </select>
				</form>
			</td>
			<td align="left">
				<input type="button" name="iter" value="Iterate/Pause" onClick="pauseDrawing();">
				<input type="button" name="reset" value="Reset" onClick="refreshData();">
				</form>
			</td>
		</tr>
	</table>
</div>

<div class="canvas-row">
  <canvas id="canvas" width="250" height="500">
    <p>Your browser is currently unsupported.</p>
  </canvas>
</div>

<div class="content-row">
	<table align="center">
		<tr>
			<td>
				<form name="outform">
			    <textarea rows="25" cols="80" name="output"></textarea>
		    </form>
			</td>
		</tr>
	</table>
</div>

</body>
</html>
